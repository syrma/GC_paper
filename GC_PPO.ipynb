{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Gym version v0.24.0 has a number of critical issues with `gym.make` such that the `reset` and `step` functions are called before returning the environment. It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n",
      "/home/romaissa/anaconda3/envs/experiments/lib/python3.7/site-packages/gym/envs/registration.py:408: UserWarning: \u001B[33mWARN: The `registry.env_specs` property along with `EnvSpecTree` is deprecated. Please use `registry` directly as a dictionary instead.\u001B[0m\n",
      "  \"The `registry.env_specs` property along with `EnvSpecTree` is deprecated. Please use `registry` directly as a dictionary instead.\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "import pybullet_envs\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#EXPERIMENT PARAMETERS: MODIFY THIS\n",
    "\n",
    "env_name = 'CartPole-v1'\n",
    "seed = 0\n",
    "n_critics = 3\n",
    "batch_size = 10000\n",
    "epochs = 200\n",
    "learning_rate = 3e-4\n",
    "opt = tf.optimizers.Adam(learning_rate)\n",
    "γ = .99\n",
    "λ = 0.97\n",
    "kl_target = 0.01\n",
    "\n",
    "#run variables\n",
    "norm_rew = False\n",
    "norm_obs = False\n",
    "kl_stop = False\n",
    "kl_rollback = False\n",
    "bootstrap = False\n",
    "\n",
    "#save directory (for kl_rollback optimization)\n",
    "os.makedirs(\"saves\", exist_ok=True)\n",
    "save_dir = tempfile.mkdtemp(dir='saves', prefix=env_name)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 120)               600       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 170       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,934\n",
      "Trainable params: 10,934\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/romaissa/anaconda3/envs/experiments/lib/python3.7/site-packages/gym/core.py:201: DeprecationWarning: \u001B[33mWARN: Function `env.seed(seed)` is marked as deprecated and will be removed in the future. Please use `env.reset(seed=seed)` instead.\u001B[0m\n",
      "  \"Function `env.seed(seed)` is marked as deprecated and will be removed in the future. \"\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(env_name)\n",
    "obs_spc = env.observation_space\n",
    "act_spc = env.action_space\n",
    "\n",
    "if act_spc.shape:\n",
    "    env = gym.wrappers.ClipAction(env)\n",
    "\n",
    "if norm_obs:\n",
    "    env = gym.wrappers.NormalizeObservation(env)\n",
    "    env = gym.wrappers.TransformObservation(env, lambda obs: tf.clip_by_value(obs, -10, 10))\n",
    "\n",
    "#seeding\n",
    "tf.random.set_seed(seed)\n",
    "env.seed(seed)\n",
    "act_spc.seed(seed)\n",
    "obs_spc.seed(seed)\n",
    "\n",
    "# policy/actor model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(120, activation='relu', input_shape=obs_spc.shape),\n",
    "    tf.keras.layers.Dense(84, activation='relu'),\n",
    "    tf.keras.layers.Dense(act_spc.shape[0] if act_spc.shape else act_spc.n)\n",
    "])\n",
    "if act_spc.shape:\n",
    "    model.log_std = tf.Variable(tf.fill(env.action_space.shape, -0.5))\n",
    "model.summary()\n",
    "\n",
    "# value/critic model\n",
    "critics = list()\n",
    "\n",
    "for _ in range(n_critics):\n",
    "    value_model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(64, activation='relu', input_shape=obs_spc.shape),\n",
    "        tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    value_model.compile('adam', loss='MSE')\n",
    "    critics.append(value_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# taken from https://github.com/openai/baselines/blob/master/baselines/common/vec_env/vec_normalize.py\n",
    "class RunningMeanStd:\n",
    "    \"\"\"Tracks the mean, variance and count of values.\"\"\"\n",
    "\n",
    "    # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Parallel_algorithm\n",
    "    def __init__(self, epsilon=1e-4, shape=()):\n",
    "        \"\"\"Tracks the mean, variance and count of values.\"\"\"\n",
    "        self.mean = np.zeros(shape, \"float64\")\n",
    "        self.var = np.ones(shape, \"float64\")\n",
    "        self.count = epsilon\n",
    "\n",
    "    def update(self, x):\n",
    "        \"\"\"Updates the mean, var and count from a batch of samples.\"\"\"\n",
    "        batch_mean = np.mean(x, axis=0)\n",
    "        batch_var = np.var(x, axis=0)\n",
    "        batch_count = x.shape[0]\n",
    "        self.update_from_moments(batch_mean, batch_var, batch_count)\n",
    "\n",
    "    def update_from_moments(self, batch_mean, batch_var, batch_count):\n",
    "        \"\"\"Updates from batch mean, variance and count moments.\"\"\"\n",
    "        self.mean, self.var, self.count = update_mean_var_count_from_moments(\n",
    "            self.mean, self.var, self.count, batch_mean, batch_var, batch_count\n",
    "        )\n",
    "\n",
    "def update_mean_var_count_from_moments(\n",
    "    mean, var, count, batch_mean, batch_var, batch_count\n",
    "):\n",
    "    \"\"\"Updates the mean, var and count using the previous mean, var, count and batch values.\"\"\"\n",
    "    delta = batch_mean - mean\n",
    "    tot_count = count + batch_count\n",
    "\n",
    "    new_mean = mean + delta * batch_count / tot_count\n",
    "    m_a = var * count\n",
    "    m_b = batch_var * batch_count\n",
    "    M2 = m_a + m_b + np.square(delta) * count * batch_count / tot_count\n",
    "    new_var = M2 / tot_count\n",
    "    new_count = tot_count\n",
    "\n",
    "    return new_mean, new_var, new_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Buffer(object):\n",
    "    def __init__(self, obs_spc, act_spc, model, critics, size, gam=0.99, lam=0.97):\n",
    "        self.ptr = 0\n",
    "        self.last_idx = 0\n",
    "        self.size = size\n",
    "        self.continuous = bool(act_spc.shape)\n",
    "\n",
    "        self.model = model\n",
    "        self.critics = critics\n",
    "\n",
    "        self.obs_buf = tf.TensorArray(obs_spc.dtype, size)\n",
    "        self.act_buf = tf.TensorArray(act_spc.dtype, size)\n",
    "        self.rew_buf = tf.TensorArray(tf.float32, size)\n",
    "        self.prob_buf = tf.TensorArray(tf.float32, size)\n",
    "\n",
    "        self.rets = []\n",
    "        self.ret_rms = RunningMeanStd(shape=())\n",
    "        self.lens = []\n",
    "\n",
    "        self.V_hats = tf.TensorArray(tf.float32, size)\n",
    "        self.gae = tf.TensorArray(tf.float32, size)\n",
    "\n",
    "        self.gam = gam\n",
    "        self.lam = lam\n",
    "\n",
    "    # @tf.function\n",
    "    def store(self, obs, act, rew, prob):\n",
    "        self.obs_buf = self.obs_buf.write(self.ptr, obs)\n",
    "        self.act_buf = self.act_buf.write(self.ptr, act)\n",
    "        self.rew_buf = self.rew_buf.write(self.ptr, rew)\n",
    "        self.prob_buf = self.prob_buf.write(self.ptr, prob)\n",
    "        self.ptr += 1\n",
    "\n",
    "    # @tf.function\n",
    "    def finish_path(self, last_obs=None):\n",
    "        current_episode = tf.range(self.last_idx, self.ptr)\n",
    "\n",
    "        #bootstrapping the remaining values if the episode was interrupted\n",
    "        if last_obs == None:\n",
    "            last_val = 0\n",
    "        else:\n",
    "            predictions = [tf.squeeze(value_model((tf.expand_dims(last_obs, 0)))) for value_model in self.critics]\n",
    "            last_val = tf.math.reduce_mean(predictions)\n",
    "\n",
    "        # last_val = tf.squeeze(self.value_model(tf.expand_dims(last_obs, 0))) if last_obs is not None else 0\n",
    "\n",
    "        length = self.ptr - self.last_idx\n",
    "        ep_rew = self.rew_buf.gather(current_episode)\n",
    "        ret = tf.reduce_sum(ep_rew) + last_val\n",
    "        self.lens.append(length)\n",
    "        self.rets.append(ret)\n",
    "\n",
    "        #(attempt at) scaling the rewards\n",
    "        if norm_rew:\n",
    "            self.ret_rms.update(np.array(self.rets))\n",
    "            ep_rew = ep_rew / tf.sqrt(tf.cast(self.ret_rms.var, tf.float32) + 1e-8)\n",
    "\n",
    "        # v_hats = discounted cumulative sum\n",
    "        discounts = tf.math.cumprod(tf.fill(ep_rew.shape, self.gam), exclusive=True)\n",
    "        v_hats = tf.math.cumsum(discounts * ep_rew, reverse=True)\n",
    "\n",
    "\n",
    "        self.V_hats = self.V_hats.scatter(current_episode, v_hats)\n",
    "\n",
    "        #Vs = tf.squeeze(value_model(self.obs_buf.gather(current_episode)), axis=1)\n",
    "\n",
    "        predictions = [tf.squeeze(value_model(self.obs_buf.gather(current_episode)), axis=1) for value_model in self.critics]\n",
    "        Vs = tf.math.reduce_mean(predictions, axis=0)\n",
    "        Vsp1 = tf.concat([Vs[1:], [last_val]], axis=0)\n",
    "        deltas = self.rew_buf.gather(current_episode) + self.gam * Vsp1 - Vs\n",
    "\n",
    "        # compute the advantage function (gae)\n",
    "        discounts = tf.math.cumprod(tf.fill(deltas.shape, self.gam * self.lam), exclusive=True)\n",
    "        gae = tf.math.cumsum(discounts * deltas, reverse=True)\n",
    "\n",
    "        #Normalise the advantage\n",
    "        gae = (gae - tf.math.reduce_mean(gae)) / (tf.math.reduce_std(gae) + 1e-8)\n",
    "\n",
    "        self.gae = self.gae.scatter(current_episode, gae)\n",
    "\n",
    "        self.last_idx = self.ptr\n",
    "\n",
    "        if self.ptr == self.size:\n",
    "            self.obs_buf = self.obs_buf.stack()\n",
    "            self.act_buf = self.act_buf.stack()\n",
    "            self.rew_buf = self.rew_buf.stack()\n",
    "            self.prob_buf = self.prob_buf.stack()\n",
    "\n",
    "            self.V_hats = self.V_hats.stack()\n",
    "            self.gae = self.gae.stack()\n",
    "\n",
    "    def approx_kl(self):\n",
    "        obs, act, logprob = self.obs_buf, self.act_buf, self.prob_buf\n",
    "\n",
    "        if self.continuous:\n",
    "            dist = tfd.MultivariateNormalDiag(model(obs), tf.exp(self.model.log_std))\n",
    "        else:\n",
    "            dist = tfd.Categorical(logits=model(obs))\n",
    "\n",
    "        new_logprob = dist.log_prob(act)\n",
    "\n",
    "        return tf.reduce_mean(logprob - new_logprob)\n",
    "\n",
    "    # @tf.function\n",
    "    def loss(self):\n",
    "        eps = 0.1\n",
    "        obs, act, adv, logprob = self.obs_buf, self.act_buf, self.gae, self.prob_buf\n",
    "\n",
    "        if self.continuous:\n",
    "            dist = tfd.MultivariateNormalDiag(model(obs), tf.exp(self.model.log_std))\n",
    "        else:\n",
    "            dist = tfd.Categorical(logits=model(obs))\n",
    "\n",
    "        new_logprob = dist.log_prob(act)\n",
    "\n",
    "        mask = tf.cast(adv >= 0, tf.float32)\n",
    "        epsilon_clip = mask * (1 + eps) + (1 - mask) * (1 - eps)\n",
    "        ratio = tf.exp(new_logprob - logprob)\n",
    "\n",
    "        return -tf.reduce_mean(tf.minimum(ratio * adv, epsilon_clip * adv))\n",
    "\n",
    "    #%%\n",
    "\n",
    "@tf.function\n",
    "def action(model, obs, env):\n",
    "    est = tf.squeeze(model(tf.expand_dims(obs, 0)), axis=0)\n",
    "    if env.action_space.shape:\n",
    "        dist = tfd.MultivariateNormalDiag(est, tf.exp(model.log_std))\n",
    "    else:\n",
    "        dist = tfd.Categorical(logits=est, dtype=env.action_space.dtype)\n",
    "\n",
    "    action = dist.sample()\n",
    "    logprob = tf.reduce_sum(dist.log_prob(action))\n",
    "\n",
    "    return action, logprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def save_model(model, save_path):\n",
    "    ckpt = tf.train.Checkpoint(model=model)\n",
    "    manager = tf.train.CheckpointManager(ckpt, save_path, max_to_keep=None)\n",
    "    manager.save()\n",
    "\n",
    "def load_model(model, load_path):\n",
    "    ckpt = tf.train.Checkpoint(model=model)\n",
    "    manager = tf.train.CheckpointManager(ckpt, load_path, max_to_keep=None)\n",
    "    ckpt.restore(manager.latest_checkpoint)\n",
    "    print(\"Restoring from {}\".format(manager.latest_checkpoint))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def run_one_episode(env, buf):\n",
    "    obs_dtype = env.observation_space.dtype\n",
    "\n",
    "    obs = env.reset()\n",
    "    obs = tf.cast(obs, obs_dtype)\n",
    "    done = False\n",
    "\n",
    "    for i in range(buf.ptr, buf.size):\n",
    "        act, prob = action(buf.model, obs, env)\n",
    "        new_obs, rew, done, _ = env.step(act.numpy())\n",
    "\n",
    "        rew = tf.cast(rew, 'float32')\n",
    "\n",
    "        buf.store(obs, act, rew, prob)\n",
    "        obs = tf.cast(new_obs, obs_dtype)\n",
    "\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    critic_start = time.time()\n",
    "    if done:\n",
    "        buf.finish_path()\n",
    "    else:\n",
    "        buf.finish_path(obs)\n",
    "\n",
    "    return time.time() - critic_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(env, batch_size, model, critics, γ, λ, save_dir):\n",
    "    obs_spc = env.observation_space\n",
    "    act_spc = env.action_space\n",
    "\n",
    "    batch = Buffer(obs_spc, act_spc, model, critics, batch_size, gam=γ, lam=λ)\n",
    "    start_time = time.time()\n",
    "\n",
    "    critic_time = 0\n",
    "    while batch.ptr < batch.size:\n",
    "        critic_time += run_one_episode(env, batch)\n",
    "\n",
    "    train_start_time = time.time()\n",
    "\n",
    "    var_list = list(model.trainable_weights)\n",
    "    if act_spc.shape:\n",
    "        var_list.append(model.log_std)\n",
    "\n",
    "    for i in range(80):\n",
    "        save_model(model, save_dir)\n",
    "        opt.minimize(batch.loss, var_list=var_list)\n",
    "\n",
    "        # do we want early stopping?\n",
    "        if not kl_stop:\n",
    "            continue\n",
    "\n",
    "        if batch.approx_kl() > 1.5 * kl_target:\n",
    "            print(f\"Early stopping at step {i}\")\n",
    "            # rollback if asked to\n",
    "            if kl_rollback:\n",
    "                load_model(model, save_dir)\n",
    "            break\n",
    "\n",
    "    train_time = time.time() - train_start_time\n",
    "    run_time = train_start_time - start_time\n",
    "\n",
    "    print('run time', run_time, 'critic time (included in run time):', critic_time, 'train time', train_time)\n",
    "    print('AvgEpRet:', tf.reduce_mean(batch.rets).numpy())\n",
    "\n",
    "    for i in range(len(critics)):\n",
    "        bootstrap_value = 0.9 if bootstrap else 1\n",
    "        mask = tf.random.uniform([batch.size]) < bootstrap_value\n",
    "        masked_obs = tf.boolean_mask(batch.obs_buf, mask)\n",
    "        masked_vhats = tf.boolean_mask(batch.V_hats, mask)\n",
    "        hist = critics[i].fit(batch.obs_buf.numpy(), batch.V_hats.numpy(), epochs=80, steps_per_epoch=1, verbose=0)\n",
    "        tf.reduce_mean(hist.history['loss']).numpy()\n",
    "\n",
    "    return batch.rets, batch.lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(epochs, env, batch_size, model, critics, γ, λ, save_dir):\n",
    "    for i in range(1, epochs + 1):\n",
    "        start_time = time.time()\n",
    "        print('Epoch: ', i)\n",
    "        batch_loss = train_one_epoch(env, batch_size, model, critics, γ, λ, save_dir)\n",
    "        now = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/romaissa/anaconda3/envs/experiments/lib/python3.7/site-packages/tree/__init__.py:312: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  return _tree.flatten(structure)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run time 15.501555919647217 critic time (included in run time): 4.530521392822266 train time 3.1431703567504883\n",
      "AvgEpRet: 21.691923\n",
      "Epoch:  2\n",
      "run time 14.278815984725952 critic time (included in run time): 3.7764406204223633 train time 2.9412949085235596\n",
      "AvgEpRet: 25.512894\n",
      "Epoch:  3\n",
      "run time 13.319865703582764 critic time (included in run time): 3.192547559738159 train time 2.9303970336914062\n",
      "AvgEpRet: 33.564663\n",
      "Epoch:  4\n"
     ]
    }
   ],
   "source": [
    "train(epochs, env, batch_size, model, critics, γ, λ, save_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}